<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>TripleNet</title>

<!-- Meta tags for search engines to crawl -->
<meta name="robots" content="index,follow">
<meta name="description" content="">
<meta name="keywords" content="Image encryption; Asymmetric encryption; Image generation; ">
<meta name="keywords" content="Ziqiang Zheng; 郑自强; Computer Vision;">
<link rel="author" href="https://zhengziqiang.github.io/">

<!-- Fonts and stuff -->
<link href="./css/css" rel="styles<!-- heet" type="text/css">
<link rel="stylesheet" type="text/css" href="./css/project.css" media="screen">
<link rel="stylesheet" type="text/css" media="screen" href="./css/iconize.css">
<script async="" src="./css/prettify.js.download"></script>


</head>

<body>
  <div id="content">
    <div id="content-inner">

      <div class="section head">
	<h1>TripleNet: Image Generation for Joint Information Hiding and Asymmetric Encryption</h1>

	<div class="authors">
	  <a href="https://zhengziqiang.github.io/">Ziqiang Zheng</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
	  <a href="https://scholar.google.com.hk/citations?user=vwOQ-UIAAAAJ&hl=zh-CN/">Yang Wu</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
		<a href="https://cfm.uestc.edu.cn/~yangyang/">Yang Yang</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
	  <a href="https://www.cis.upenn.edu/~jshi//">Jianbo Shi</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
	</div>

	<div class="online">
	  <a href=""><font color="#FF0000">Online demo</font></a>
	</div class='section teaser'>

	<!-- <div class="venue">Preprint Manuscript (<a href="https://arxiv.org/" target="_blank">Arxiv</a>) 2018</div> -->
      </div>

      <center><img src="./TripleNet/demo.jpg" border="0" width="90%"></center>

<div class="section abstract">
	<h2>Abstract</h2>
	<br>
	<p>
We propose a unified framework, TripleNet, to perform joint information hiding and asymmetric encryption, via an interplay of three different neural networks. Using two sets of images, from two distinct domains, we generate pairs of public keys and private keys using a convolutional network jointly trained for image reconstruction. Two conditional generative adversarial networks are used for public key based encryption and private key based decryption, respectively. We achieve public key-based encryption and private key-based decryption with a Triplet Cycle of Adversarial networks. We show that such interaction of the triplet can result in effective joint information hiding and encryption with neural networks, which has never been explored before as far as we are aware. The proposed framework is different from current cryptography and steganography schemes while integrating the advantages o both two kinds of methods. TripleNet provides robust security and the diversity of both keys. We conducted a comprehensive analysis to verify the effectiveness of TripleNet with various datasets, and provide a comparison with related image-to-image translation approaches for symmetric encryption and image steganography methods. Besides, our TripleNet can also be applied to encrypt multimedia data such as text and audio. Extensive experiments confirm TripleNet's effectiveness and security under various settings, in comparison with other most related approaches.
	</p>
      </div>

<div class="section architecture">
	<h2>Architecture</h2>
	<br>
	<center><img src="./TripleNet/network.jpg" border="0" width="80%"></center>
</div>


<div class="section comparison">
	<h2>Comparison with previous work</h2>
	<br>
	<p>Compared with previous symmetric encryption framework and steganography, we argue the proposed method have two main superiorities.</p>
	<ul>
	<li>Compared with cryptography algorithms, the encrypted output generated by our TripleNet looks like a <strong>natural</strong> image, which is misleading. Through this, our TripleNet can perform safe transmission without attracting other's attention.</li>
	<li>Even though the original cover is accessible or exposed by the public, the attacker cannot detect or decode the private message by comparing the original cover and the encrypted output. In other words, our method posses high <strong>security</strong> and <strong>robustness</strong> against statistical attacks.</li>
	</ul>
	<center><img src="./TripleNet/comparison.png" border="0" width="100%"></center>
</div>

<div class="section comparison">
	<h2>Visual results</h2>
	<p>Visual encryption results at different settings. Left: the images in <font color="#FF0000">red</font> box show the encryption and decryption results with varying values of &alpha; for interpolated images.  Observe that the encrypted images are changed by adopting different &alpha;. Right:  images in <font color="#00FF00">green</font> box show the results of resizing and random pasting setting.  Observe that the pasting location of the message image has a large impact on the synthesized images, which lead to diversified outputs.  We show that the wrong private keys prevent the correct reconstruction of the private message.</p>
	<br>
	<center><img src="./TripleNet/visual.jpg" border="0" width="90%"></center>
</div>


<div class="section Visual">

	<h2>Downloads</h2>
<!-- <HR size=2> -->

<ul>
	<li>
		  <a href="https://arxiv.org/pdf/1905.11582.pdf" target="_blank">Paper</a>
	</li>
	<li>
		  <a href="https://github.com/zhengziqiang/EncryptGAN" target="_blank">Codes</a> (have fun!)
	</li>
</ul>
</div>

<br>
		<div class="section Presentation">
			<h2>Demo presentations</h2>
			<center><h3>Encrypt the <font color="#FF0000">text</font> into one image (<i>asymmetric encryption</i>)</h3></center>
			<center><embed src="./TripleNet/text.mp4" height="250" width="400"/></center>
			<center><p>We aim to encrypt private text information to an irrelevant image and perform the asymmetric encryption, which means that a wrong private key cannot lead to a successful reconstruction.</p></center>
			<br>
			<br>
			<br>
			<center><h3>Encrypt the <font color="#FF0000">audio</font> into one image (<i>asymmetric encryption</i>)</h3></center>
			<center><embed src="./TripleNet/audio.mp4" height="250" width="400"/></center>
			<center><p>We aim to encrypt private an audio piece to an irrelevant image and perform the asymmetric encryption, which means that a wrong private key cannot lead to a successful reconstruction. <font color="#FF0000">Undesired noise! Attention!</font></p></center>
			<br>
			<br>
			<br>
			<center><h3>Asymmetric <font color="#FF0000">image</font> encryption (<i>interpolation case</i>)</h3></center>
			<center><embed src="./TripleNet/interp_new.mp4" height="200" width="600"/></center>
			<center><p>We combine a private secret message image and an irrelevant container image to a <i>composite</i> image through a traditional image blending method. The we perform the asymmetric encryption. Varying values of &alpha; could lead to different encrypted outputs. A wrong private key cannot result in a correct reconstruction (only <font color="#FF0000">meaningless noise</font>).</p></center>
			<br>
			<br>
			<br>
			<center><h3>Asymmetric image encryption (<i>smaller images (random paster)</i>)</h3></center>
			<center><embed src="./TripleNet/size_location_key.mp4" height="250" width="400"/></center>
			<center><p>To enhance the diversity of the encrypted outputs and promote the security of proposed TripleNet, we target to put a smaller size image to a larger container image. Thus, we could have a lot of different spatial choices. Changing the location could synthesize different synthesized outputs, which indicates a large sample diversity. A wrong private key cannot result in a correct reconstruction (only <font color="#FF0000">container image</font>).</p></center>
			<br>
			<br>
			<br>
			<center><h3>Analysis of sensitiveness of private key</h3></center>
			<center><embed src="./TripleNet/noise.mp4" height="250" width="400"/></center>
			<center><p>We add different scales of Gaussian noise to the private key to evaluate the sensitiveness of the private key. More details could be found in our paper.</p></center>
		</div>


<br>

<div class="section citation">

	<h2>Citation</h2>
	<div class="section bibtex">
	  <pre>@article{zheng2019encryptgan,
  title={EncryptGAN: Image Steganography with Domain Transform},
  author={Zheng, Ziqiang and Liu, Hongzhi and Yu, Zhibin and Zheng, Haiyong and Wu, Yang and Yang, Yang and Shi, Jianbo},
  journal={arXiv preprint arXiv:1905.11582},
  year={2019}
}</pre>
	  </div>
      </div>

</div></div></body></html>