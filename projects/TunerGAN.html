<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>Property Tunable Image Manipulation with Self-Generated Supervision</title>

<!-- Meta tags for search engines to crawl -->
<meta name="robots" content="index,follow">
<meta name="description" content="">
<meta name="keywords" content="Property tuning; GAN; Image generalization; Self-supervision">
<meta name="keywords" content="Ziqiang Zheng; 郑自强; Computer Vision;">
<link rel="author" href="https://zhengziqiang.github.io/">

<!-- Fonts and stuff -->
<link href="./css/css" rel="styles<!-- heet" type="text/css">
<link rel="stylesheet" type="text/css" href="./css/project.css" media="screen">
<link rel="stylesheet" type="text/css" media="screen" href="./css/iconize.css">
<script async="" src="./css/prettify.js.download"></script>


</head>

<body>
  <div id="content">
    <div id="content-inner">

      <div class="section head">
	<h1>Property Tunable Image Manipulation with Self-Generated Supervision</h1>

	<div class="authors">
	  <a href="https://zhengziqiang.github.io/">Ziqiang Zheng</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
	  <a href="https://scholar.google.com.hk/citations?user=vwOQ-UIAAAAJ&hl=zh-CN/">Yang Wu</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
	  <a href="https://www.cis.upenn.edu/~jshi//">Jianbo Shi</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
	</div>

	<div class="affiliations">

	  <p>UISEE company</p>
	</div class='section teaser'>

	<!-- <div class="venue">Preprint Manuscript (<a href="https://arxiv.org/" target="_blank">Arxiv</a>) 2018</div> -->
      </div>

      <center><img src="./TunerGAN/tunergan_explain.jpg" border="0" width="90%"></center>

<div class="section abstract">
	<h2>Abstract</h2>
	<br>
	<p>
We propose an instance-invariant image synthesis framework steered by continuously tunable properties. The key challenge is that training data distribution is often sparse, including the extreme case of having only one instance sample. We introduce an infinite synthetically-generated scheme to continuously manipulate the input image. For each training image, the model self-generates its manipulated image according to the synthesized desired property label as the self-supervision for the model's training. A key objective is to produce desired property change while maintaining instance-invariance. We implement this using a TunerGAN: infusing parallel streams of input-output messages to the GAN network. The messages, once decoded into feature maps represent tunable properties and instance invariance. The output messages extracted from the synthesized image, are self-checked with the input messages to ensure instance-level synthesis is done correctly: \emph{e.g.}, face rotated correctly with identity preserved. Our framework is general for image manipulation and we have conducted experiments on a variety of tasks to demonstrate its effectiveness.
	</p>
      </div>





<div class="section architecture">
	<h2>Architecture</h2>
	<br>
	<center><img src="./TunerGAN/tunergan.jpg" border="0" width="90%"></center>
</div>



<div class="section download">

	<h2>Downloads</h2>
<!-- <HR size=2> -->

<ul>
	<li>
		  <a href="" target="_blank">Paper</a>
	</li>


</ul>
</div>








<br>

<div class="section citation">

	<h2>Citation</h2>
	<div class="section bibtex">
	  <pre></pre>
	  </div>
      </div>

</div></div></body></html>