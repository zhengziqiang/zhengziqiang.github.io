<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>Task-driven Webpage Saliency</title>

<!-- Meta tags for search engines to crawl -->
<meta name="robots" content="index,follow">
<meta name="description" content="In this paper, we present an end-to-end learning framework for predicting task-driven visual saliency on webpages. Given a webpage, we propose a convolutional neural network to predict where people look at it under different task conditions. Inspired by the observation that given a specific task, human attention is strongly correlated with certain semantic components on a webpage (e.g., images, buttons and input boxes), our network explicitly disentangles saliency prediction into two independent sub-tasks: task-specific attention shift prediction and task-free saliency prediction. The task-specific branch estimates task-driven attention shift over a webpage from its semantic components, while the task-free branch infers visual saliency induced by visual features of the webpage. The outputs of the two branches are combined to produce the final prediction. Such a task decomposition framework allows us to efficiently learn our model from a small-scale task-driven saliency dataset with sparse labels (captured under a single task condition). Experimental results show that our method outperforms the baselines and prior works, achieving state-of-the-art performance on a newly collected benchmark dataset for task-driven webpage saliency detection.">
<meta name="keywords" content="Webpage analysis; Image steganography; Task-specific saliency;">
<meta name="keywords" content="Ziqiang Zheng; 郑自强; Computer Vision;">
<link rel="author" href="https://zhengziqiang.github.io/">

<!-- Fonts and stuff -->
<link href="./css/css" rel="styles<!-- heet" type="text/css">
<link rel="stylesheet" type="text/css" href="./css/project.css" media="screen">
<link rel="stylesheet" type="text/css" media="screen" href="./Task-driven-Webpage-Saliency/iconize.css">
<script async="" src="./css/prettify.js.download"></script>
 

</head>

<body>
  <div id="content">
    <div id="content-inner">
      
      <div class="section head">
	<h1>Composition-Aware Image Steganography through Adversarial Self-Generated Supervision</h1>

	<div class="authors">
	  <a href="https://zhengziqiang.github.io/">Ziqiang Zheng</a>
	  <a href="http://www.cs.cityu.edu.hk/~jianbjiao2/">Yuanmeng Hu</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
	  <a href="https://scholar.google.com.hk/citations?user=KDdkZKQAAAAJ&hl=zh-CN">Yi Bin</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
		<a href="https://interxuxing.github.io/">Xing Xu</a>
	  <a href="https://cfm.uestc.edu.cn/~yangyang/">Yang Yang</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
	  <a href="https://cfm.uestc.edu.cn/~shenht/">Heng Tao Shen</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
	</div>

	<div class="affiliations">
	  <p><a href="https://www.uestc.edu.cn/">University of Electronic Science and Technology of China</a></p>
	</div class='section teaser'>
	<div class="online_demo">
	  <p><a href="/">Online demo</a></p>
	</div class='section teaser'>

	<!-- <div class="venue">Preprint Manuscript (<a href="https://arxiv.org/" target="_blank">Arxiv</a>) 2018</div> -->
      </div>
      
      <center><img src="./CAIS/demo.png" border="0" width="90%"></center>

<div class="section abstract">
	<h2>Abstract</h2>
	<br>
	<p>
Steganography is an important and prevailing information hiding tool to perform secret message transmission in an open environment. Existing steganography methods can mainly fall into two categories: pre-defined rule-based and data-driven methods. The former is susceptible to the statistical attack while the latter adopts the deep convolution neural networks to promote security under statistical attack. However, the deep learning-based methods suffer from perceptible artificial artifacts. In this paper, we introduce a novel Composition-Aware Image Steganography termed \textbf{CAIS} to guarantee both visual security and robustness to attack through self-generated supervision. The key innovation is an adversarial composition estimation module to integrate rule-based and deep generative adversarial methods. We perform a rule-based image blending method to obtain infinite synthetically data-label pairs and perform an auxiliary adversarial composition estimation task. The innovative self-generated supervision could largely promote the ability to recognize message patterns from steganographic outputs, which results in better steganography performance. Furthermore, an effective Global-and-Part checking is designed to alleviate visual artifacts caused by hiding secret information. We conduct a comprehensive analysis of CAIS from various aspects such as security and robustness to verify the superior performance of the proposal. Experimental results on three large-scale widely-used datasets show the superior performance of our CAIS compared with several state-of-the-art approaches.
	</p>
      </div>


      


<div class="section architecture">
	<h2>Architecture</h2>
	<br>
	<center><img src="./CAIS/framework.png" border="0" width="90%"></center>
</div>


<div class="section download">

	<h2>Downloads</h2>
<!-- <HR size=2> -->

<ul>
	<li>
		  <a href="" target="_blank">Paper</a>
	</li>
	<li>
		  <a href="https://github.com/zhengziqiang/CAIS" target="_blank">Codes</a>
	</li>

</ul>
</div>


<br>

<div class="section Related Work">

	<h2>Related work</h2>
<!-- <HR size=2> -->

<ul>
	<li>
		  <a href="https://github.com/harveyslash/Deep-Steganography" target="_blank">Steganography</a>
	</li>
	<li>
		  <a href="https://github.com/saadzia10/Steganography-Deep-Learning" target="_blank">Deep-stego</a>
	</li>

	<li>
		  <a href="https://github.com/Marcovaldong/ISGAN" target="_blank">ISGAN</a>
	</li>
	<li>
		  <a href="https://github.com/ChaoningZhang/Universal-Deep-Hiding" target="_blank">UDH</a>
	</li>
</ul>
		<h2>Steganography detection</h2>
<!-- <HR size=2> -->

<ul>
	<li>
		  <a href="https://github.com/DXQer/Cov-Pooling-Steganalytic-Network" target="_blank">CoNet</a>
	</li>
	<li>
		  <a href="https://github.com/brijeshiitg/Pytorch-implementation-of-SRNet" target="_blank">SRNet</a>
	</li>
</ul>
</div>

<br>

<div class="section citation">

	<h2>Citation</h2>
	<div class="section bibtex">
	  <pre>Submitted to TNNLS, Major revision</pre>
	  </div>
      </div>

</div></div></body></html>